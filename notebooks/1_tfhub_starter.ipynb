{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "!pip install tensorflow_hub -q"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## "
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. The model weights in a hub.KerasLayer are set to non-trainable by default. See the section on fine-tuning below for how to change that. Weights are shared between all applications of the same layer object, as usual in Keras.\n",
    "\n",
    "## 2. Using a SavedModel from TensorFlow Hub (or other HTTPS servers that implement its hosting protocol) downloads and decompresses it to the local filesystem if not already present. The environment variable TFHUB_CACHE_DIR can be set to override the default temporary location for caching the downloaded and uncompressed SavedModels. For details, see Caching.\n",
    "\n",
    "## 3. Training the already-trained variables of an imported SavedModel together with those of the model around it is called fine-tuning the SavedModel. This can result in better quality, but often makes the training more demanding (may take more time, depend more on the optimizer and its hyperparameters, increase the risk of overfitting and require dataset augmentation, esp. for CNNs). We advise SavedModel consumers to look into fine-tuning only after having established a good training regime, and only if the SavedModel publisher recommends it.\n",
    "\n",
    "## 4. layer = hub.KerasLayer(..., trainable=True)\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "\n",
    "import PIL.Image as Image\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "IMAGE_SHAPE = (224, 224)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "mobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "classifier = tf.keras.Sequential([\n",
    "    hub.KerasLayer(mobilenet_v2, input_shape=IMAGE_SHAPE+(3,))\n",
    "])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2022-01-28 22:23:37.731380: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-28 22:23:37.731627: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Metal device set to: Apple M1\n",
      "\n",
      "systemMemory: 8.00 GB\n",
      "maxCacheSize: 2.67 GB\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "def preprocess_inference_image(img: str):\n",
    "    img = Image.open(img).resize(IMAGE_SHAPE)\n",
    "    img = np.array(img)/255.0\n",
    "    return img"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "img = preprocess_inference_image('../sample_image.png')\n",
    "img_expanded = img[np.newaxis, ...]\n",
    "img_expanded.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 224, 224, 3)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "result = classifier.predict(img_expanded)\n",
    "result.shape"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2022-01-27 21:25:49.946674: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2022-01-27 21:25:49.950541: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-27 21:25:50.039434: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1, 1001)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "predicted_class = tf.math.argmax(result[0], axis=-1)\n",
    "predicted_class"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=405>"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "labels_path = '../ImageNetLabels.txt'\n",
    "imagenet_labels = np.array(open(labels_path).read().splitlines())\n",
    "imagenet_labels"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['background', 'tench', 'goldfish', ..., 'bolete', 'ear',\n",
       "       'toilet tissue'], dtype='<U30')"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "predicted_class_name = imagenet_labels[predicted_class]\n",
    "predicted_class_name\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'airliner'"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "converter = tf.lite.TFLiteConverter.from_keras_model(classifier)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "tf_lite_model = converter.convert()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "2022-01-28 22:24:56.090458: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/mf/f40qxhc90mj15mlg0g5g3sd80000gn/T/tmph0rp80gg/assets\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "INFO:tensorflow:Assets written to: /var/folders/mf/f40qxhc90mj15mlg0g5g3sd80000gn/T/tmph0rp80gg/assets\n",
      "2022-01-28 22:24:57.256289: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2022-01-28 22:24:57.256592: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-01-28 22:24:57.256996: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-01-28 22:24:57.257011: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2022-01-28 22:24:57.257962: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-01-28 22:24:57.286865: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1137] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 1652 nodes (1386), 2458 edges (2192), time = 17.031ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.34ms.\n",
      "\n",
      "2022-01-28 22:24:58.499396: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:351] Ignored output_format.\n",
      "2022-01-28 22:24:58.499430: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:354] Ignored drop_control_dependency.\n",
      "2022-01-28 22:24:58.566536: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:210] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "with open('/Users/virajdatt/Desktop/mvnet_converted.tflite', 'wb') as f:\n",
    "  f.write(tf_lite_model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Could not open '/Users/virajdatt/Desktop/mvnet_converted.tflite'.",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/mf/f40qxhc90mj15mlg0g5g3sd80000gn/T/ipykernel_21286/4265808282.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/virajdatt/Desktop/mvnet_converted.tflite'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/lib/python3.9/site-packages/tensorflow/lite/python/interpreter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_path, model_content, experimental_delegates, num_threads, experimental_op_resolver_type, experimental_preserve_all_tensors)\u001b[0m\n\u001b[1;32m    363\u001b[0m       ]\n\u001b[1;32m    364\u001b[0m       self._interpreter = (\n\u001b[0;32m--> 365\u001b[0;31m           _interpreter_wrapper.CreateWrapperFromFile(\n\u001b[0m\u001b[1;32m    366\u001b[0m               \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_resolver_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_op_registerers_by_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m               custom_op_registerers_by_func, experimental_preserve_all_tensors))\n",
      "\u001b[0;31mValueError\u001b[0m: Could not open '/Users/virajdatt/Desktop/mvnet_converted.tflite'."
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "9856851bd649d589f665b7dab82e57037201f90d2f14c285519476a7544379c3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}